{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ctello-austral/labo2025v/blob/mi_rama/src/ensembles/594_TareaHogar_05_prueba3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea para el Hogar 05"
      ],
      "metadata": {
        "id": "0cEmzeUKFkPh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta Tarea para el Hogar 05 se entrega el final de la cuarta clase\n",
        "<br> se espera de usted que intente avanzar con los desafios propuestos y que los traiga terminados para la Clase 05 que será el miercoles 03 de septiembre"
      ],
      "metadata": {
        "id": "nSICPpyTGQmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  1. Overfitting the Public Leaderboard"
      ],
      "metadata": {
        "id": "DenyKXkiJ5JN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leer  https://medium.com/hmif-itb/overfitting-the-leaderboard-da25172ac62e\n",
        "( 8 minutos )"
      ],
      "metadata": {
        "id": "l-K2_ZsZGrVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Hiperparámetros del LightGBM"
      ],
      "metadata": {
        "id": "K9GkTOk5J9t3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los objetivos de esta tarea son:\n",
        "\n",
        "\n",
        "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
        "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
        "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
        "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
        "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
        "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
      ],
      "metadata": {
        "id": "VmEFy0ukKL5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
        "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
      ],
      "metadata": {
        "id": "5yvlS6JQLRMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
        "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
      ],
      "metadata": {
        "id": "eydI4YNAsFaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
        "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
        "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
      ],
      "metadata": {
        "id": "RzU4S0SeMcpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
        "* https://machinelearningmastery.com/light-gradient-boosted-machine-lightgbm-ensemble/\n",
        "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
        "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
        "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
        "\n",
        "\n",
        "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
        "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
      ],
      "metadata": {
        "id": "LNptUgI_NWWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El desafío de esta tarea es:\n",
        "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
        "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
        "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
      ],
      "metadata": {
        "id": "WpUThBojODyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1  Seteo del ambiente en Google Colab"
      ],
      "metadata": {
        "id": "PX0qg_c0yqob"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9LpZCst5a7Zs",
        "outputId": "8a611a34-cd8a-4af1-c2b1-bbeebf5c1493",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/.drive\n"
          ]
        }
      ],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XWLelftXa7Zt",
        "outputId": "9c9e581a-a16e-4003-e249-afc08e1fd5d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/labo1\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/labo1\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/austral2025-af91/dataset_pequeno.csv\"\n",
        "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Optimizacion Hiperparámetros"
      ],
      "metadata": {
        "id": "oSKhZRToy2F7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ],
      "metadata": {
        "id": "2kwPpHAtSmix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1 Inicio"
      ],
      "metadata": {
        "id": "xp4-Bj3aYI8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "limpio el ambiente de R"
      ],
      "metadata": {
        "id": "zy8YTZfESxeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "gBq__iAdQliq",
        "outputId": "111e9e5e-28e9-4e7d-c760-4e2dba365998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'Mon Nov 03 11:11:31 PM 2025'"
            ],
            "text/markdown": "'Mon Nov 03 11:11:31 PM 2025'",
            "text/latex": "'Mon Nov 03 11:11:31 PM 2025'",
            "text/plain": [
              "[1] \"Mon Nov 03 11:11:31 PM 2025\""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ],
      "metadata": {
        "id": "7rdVrBojS1IV",
        "outputId": "15b19880-d38b-42af-d68f-d9090026be64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>Ncells</th><td> 660381</td><td>35.3</td><td>1454477</td><td>77.7</td><td>1454477</td><td>77.7</td></tr>\n",
              "\t<tr><th scope=row>Vcells</th><td>1226627</td><td> 9.4</td><td>8388608</td><td>64.0</td><td>1975128</td><td>15.1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 2 × 6 of type dbl\n\n| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n|---|---|---|---|---|---|---|\n| Ncells |  660381 | 35.3 | 1454477 | 77.7 | 1454477 | 77.7 |\n| Vcells | 1226627 |  9.4 | 8388608 | 64.0 | 1975128 | 15.1 |\n\n",
            "text/latex": "A matrix: 2 × 6 of type dbl\n\\begin{tabular}{r|llllll}\n  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n\\hline\n\tNcells &  660381 & 35.3 & 1454477 & 77.7 & 1454477 & 77.7\\\\\n\tVcells & 1226627 &  9.4 & 8388608 & 64.0 & 1975128 & 15.1\\\\\n\\end{tabular}\n",
            "text/plain": [
              "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
              "Ncells  660381 35.3 1454477    77.7 1454477  77.7\n",
              "Vcells 1226627  9.4 8388608    64.0 1975128  15.1"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2 Carga de Librerias"
      ],
      "metadata": {
        "id": "kuPfQ7ksjwW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cargo las librerias que necesito\n",
        "require(\"data.table\")\n",
        "require(\"parallel\")\n",
        "\n",
        "if( !require(\"primes\") ) install.packages(\"primes\")\n",
        "require(\"primes\")\n",
        "\n",
        "if( !require(\"utils\") ) install.packages(\"utils\")\n",
        "require(\"utils\")\n",
        "\n",
        "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
        "require(\"rlist\")\n",
        "\n",
        "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
        "require(\"yaml\")\n",
        "\n",
        "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")\n",
        "\n",
        "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")\n",
        "\n",
        "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")"
      ],
      "metadata": {
        "id": "lVyxLaJ1j1J_",
        "outputId": "7102d99a-8857-420d-c6f6-7a68094a6199",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: data.table\n",
            "\n",
            "Loading required package: parallel\n",
            "\n",
            "Loading required package: primes\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘primes’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: primes\n",
            "\n",
            "Loading required package: rlist\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘rlist’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘XML’\n",
            "\n",
            "\n",
            "Loading required package: rlist\n",
            "\n",
            "Loading required package: yaml\n",
            "\n",
            "Loading required package: lightgbm\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘lightgbm’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: lightgbm\n",
            "\n",
            "Loading required package: DiceKriging\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘DiceKriging’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: DiceKriging\n",
            "\n",
            "Loading required package: mlrMBO\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘mlrMBO’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘fastmatch’, ‘RcppArmadillo’, ‘mlr’, ‘ParamHelpers’, ‘smoof’, ‘BBmisc’, ‘checkmate’, ‘lhs’, ‘parallelMap’\n",
            "\n",
            "\n",
            "Loading required package: mlrMBO\n",
            "\n",
            "Loading required package: mlr\n",
            "\n",
            "Loading required package: ParamHelpers\n",
            "\n",
            "Loading required package: smoof\n",
            "\n",
            "Loading required package: checkmate\n",
            "\n",
            "\n",
            "Attaching package: ‘checkmate’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:DiceKriging’:\n",
            "\n",
            "    checkNames\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.3 Definicion de Parametros"
      ],
      "metadata": {
        "id": "Iz-6Qt6BUaA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "aqui debe cargar SU semilla primigenia\n",
        "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
      ],
      "metadata": {
        "id": "cOdlKd7lUm2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM <- list()\n",
        "PARAM$experimento <- 5942\n",
        "PARAM$semilla_primigenia <- 310019\n"
      ],
      "metadata": {
        "id": "ASYkebOu2mF6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM$kaggle$competencia <- \"labo-i-2025-virtual-analista-sr\"\n",
        "PARAM$kaggle$cortes <- seq(10000, 12000, by= 500)"
      ],
      "metadata": {
        "id": "ezOhQdbA293o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
        "# undersampling de 1.0  implica tomar TODOS los datos\n",
        "\n",
        "PARAM$trainingstrategy$undersampling <- 0.5"
      ],
      "metadata": {
        "id": "jtB0Lub42rHO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametros LightGBM\n",
        "\n",
        "PARAM$hyperparametertuning$xval_folds <- 5\n",
        "\n",
        "# parametros fijos del LightGBM que se pisaran con la parte variable de la BO\n",
        "PARAM$lgbm$param_fijos <-  list(\n",
        "  boosting= \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
        "  objective= \"binary\",\n",
        "  metric= \"auc\",\n",
        "  first_metric_only= FALSE,\n",
        "  boost_from_average= TRUE,\n",
        "  feature_pre_filter= FALSE,\n",
        "  force_row_wise= TRUE, # para reducir warnings\n",
        "  verbosity= -100,\n",
        "\n",
        "  seed= PARAM$semilla_primigenia,\n",
        "\n",
        "  max_depth= -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
        "  min_gain_to_split= 0, # min_gain_to_split >= 0\n",
        "  min_sum_hessian_in_leaf= 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
        "  lambda_l1= 0.0, # lambda_l1 >= 0.0\n",
        "  lambda_l2= 0.0, # lambda_l2 >= 0.0\n",
        "  max_bin= 31L, # lo debo dejar fijo, no participa de la BO\n",
        "\n",
        "  bagging_fraction= 1.0, # 0.0 < bagging_fraction <= 1.0\n",
        "  pos_bagging_fraction= 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
        "  neg_bagging_fraction= 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  is_unbalance= FALSE, #\n",
        "  scale_pos_weight= 1.0, # scale_pos_weight > 0.0\n",
        "\n",
        "  drop_rate= 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  max_drop= 50, # <=0 means no limit\n",
        "  skip_drop= 0.5, # 0.0 <= skip_drop <= 1.0\n",
        "\n",
        "  extra_trees= FALSE,\n",
        "\n",
        "  num_iterations= 1200,\n",
        "  learning_rate= 0.02,\n",
        "  feature_fraction= 0.5,\n",
        "  num_leaves= 750,\n",
        "  min_data_in_leaf= 5000\n",
        ")\n"
      ],
      "metadata": {
        "id": "OFxm-xiNUOJX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
        "<br> si es un numero entero debe ir  makeIntegerParam\n",
        "<br> si es un numero real (con decimales) debe ir  makeNumericParam\n",
        "<br> es muy importante leer cuales son un lower y upper  permitidos y ademas razonables"
      ],
      "metadata": {
        "id": "D5Yj-JV4yvOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
        "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
        "\n",
        "  makeNumericParam(\"learning_rate\",        lower = 0.01,  upper = 0.1),\n",
        "  makeIntegerParam(\"num_leaves\",           lower = 32,    upper = 512),\n",
        "  makeIntegerParam(\"min_data_in_leaf\",     lower = 5,     upper = 2000),\n",
        "  makeIntegerParam(\"num_iterations\",       lower = 100,   upper = 1200),\n",
        "  makeNumericParam(\"feature_fraction\",     lower = 0.3,   upper = 0.9),\n",
        "  makeNumericParam(\"bagging_fraction\",     lower = 0.5,   upper = 1.0),\n",
        "  makeNumericParam(\"lambda_l2\",            lower = 1e-6,  upper = 10),\n",
        "  makeNumericParam(\"scale_pos_weight\",     lower = 20,    upper = 160)\n",
        ")\n"
      ],
      "metadata": {
        "id": "jENpR26ZyuS8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization\n",
        "<br> 30 es un valor muy tacaño, pero corre rápido\n",
        "<br> deberia partir de 50, alcanzando los 100 si se dispone de tiempo"
      ],
      "metadata": {
        "id": "-_RPFUb3zMoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM$hyperparametertuning$iteraciones <- 50 # iteraciones bayesianas"
      ],
      "metadata": {
        "id": "q5Rd3pnbzSiG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.4  Preprocesamiento"
      ],
      "metadata": {
        "id": "4RWZXL1VZjMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento_folder <- paste0(\"HT\", PARAM$experimento)\n",
        "dir.create(experimento_folder, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
      ],
      "metadata": {
        "id": "j3toG9-lZm4K"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
      ],
      "metadata": {
        "id": "FM3lxKoLZ643"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train <- dataset[foto_mes %in% c(202107)]"
      ],
      "metadata": {
        "id": "OsJ-91UeZ-I_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paso la clase a binaria que tome valores {0,1}  enteros\n",
        "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
        "\n",
        "dataset_train[,\n",
        "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
        "]"
      ],
      "metadata": {
        "id": "vrWE7BE0aB2J"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defino los datos que forma parte del training\n",
        "# aqui se hace el undersampling de los CONTINUA\n",
        "# notar que para esto utilizo la SEGUNDA semilla\n",
        "\n",
        "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
        "dataset_train[, azar := runif(nrow(dataset_train))]\n",
        "dataset_train[, training := 0L]\n",
        "\n",
        "dataset_train[\n",
        "  foto_mes %in% c(202107) &\n",
        "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
        "  training := 1L\n",
        "]"
      ],
      "metadata": {
        "id": "jP7YlQBnaW6W"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# los campos que se van a utilizar\n",
        "\n",
        "campos_buenos <- setdiff(\n",
        "  colnames(dataset_train),\n",
        "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
        ")"
      ],
      "metadata": {
        "id": "xElu4s5W4rX7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[training == 1L, clase01],\n",
        "  free_raw_data= FALSE\n",
        ")\n",
        "\n",
        "nrow(dtrain)\n",
        "ncol(dtrain)"
      ],
      "metadata": {
        "id": "PppMHcGYaaol",
        "outputId": "803263de-9ac0-4bdf-9336-be2918c818c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "83503"
            ],
            "text/markdown": "83503",
            "text/latex": "83503",
            "text/plain": [
              "[1] 83503"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "154"
            ],
            "text/markdown": "154",
            "text/latex": "154",
            "text/plain": [
              "[1] 154"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2.5 Configuracion Bayesian Optimization"
      ],
      "metadata": {
        "id": "Ta-EkOu3cphF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# En el argumento x llegan los parmaetros de la bayesiana\n",
        "#  devuelve la AUC en cross validation del modelo entrenado\n",
        "\n",
        "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
        "\n",
        "  # x pisa (o agrega) a param_fijos\n",
        "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
        "\n",
        "  # entreno LightGBM\n",
        "  modelocv <- lgb.cv(\n",
        "    data= dtrain,\n",
        "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
        "    stratified= TRUE,\n",
        "    param= param_completo\n",
        "  )\n",
        "\n",
        "  # obtengo la ganancia\n",
        "  AUC <- modelocv$best_score\n",
        "\n",
        "  # hago espacio en la memoria\n",
        "  rm(modelocv)\n",
        "  gc(full= TRUE, verbose= FALSE)\n",
        "\n",
        "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
        "\n",
        "  return(AUC)\n",
        "}"
      ],
      "metadata": {
        "id": "cjgfurjdfiXb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui comienza la configuracion de la Bayesian Optimization\n",
        "\n",
        "# en este archivo quedan la evolucion binaria de la BO\n",
        "kbayesiana <- \"bayesiana.RDATA\"\n",
        "\n",
        "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
        "\n",
        "configureMlr(show.learner.output= FALSE)\n",
        "\n",
        "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
        "# por favor, no desesperarse por lo complejo\n",
        "\n",
        "obj.fun <- makeSingleObjectiveFunction(\n",
        "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
        "  minimize= FALSE, # estoy Maximizando la ganancia\n",
        "  noisy= TRUE,\n",
        "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
        "  has.simple.signature= FALSE # paso los parametros en una lista\n",
        ")\n",
        "\n",
        "# cada 600 segundos guardo el resultado intermedio\n",
        "ctrl <- makeMBOControl(\n",
        "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
        "  save.file.path= kbayesiana\n",
        ") # se graba cada 600 segundos\n",
        "\n",
        "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
        "ctrl <- setMBOControlTermination(\n",
        "  ctrl,\n",
        "  iters= PARAM$hyperparametertuning$iteraciones\n",
        ") # cantidad de iteraciones\n",
        "\n",
        "# defino el método estandar para la creacion de los puntos iniciales,\n",
        "# los \"No Inteligentes\"\n",
        "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
        "\n",
        "# establezco la funcion que busca el maximo\n",
        "surr.km <- makeLearner(\n",
        "  \"regr.km\",\n",
        "  predict.type= \"se\",\n",
        "  covtype= \"matern3_2\",\n",
        "  control= list(trace= TRUE)\n",
        ")\n"
      ],
      "metadata": {
        "id": "WLi_o1hocvN-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2.6 Corrida Bayesian Optimization"
      ],
      "metadata": {
        "id": "_uUeVo5pc4zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inicio la optimizacion bayesiana, retomando si ya existe\n",
        "# es la celda mas lenta de todo el notebook\n",
        "\n",
        "if (!file.exists(kbayesiana)) {\n",
        "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
        "} else {\n",
        "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
        "}"
      ],
      "metadata": {
        "id": "RcABNaKGciaz",
        "outputId": "3f32cf86-7609-47a0-ccb4-6418d5c53da0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing y column(s) for design. Not provided.\n",
            "\n",
            "Mon Nov 03 11:59:23 PM 2025 AUC 0.924567803018671\n",
            "\n",
            "Tue Nov 04 12:01:41 AM 2025 AUC 0.925473702609938\n",
            "\n",
            "Tue Nov 04 12:02:19 AM 2025 AUC 0.927363411850971\n",
            "\n",
            "Tue Nov 04 12:04:30 AM 2025 AUC 0.926235430111192\n",
            "\n",
            "Tue Nov 04 12:05:45 AM 2025 AUC 0.925904479549473\n",
            "\n",
            "Tue Nov 04 12:06:23 AM 2025 AUC 0.928151945774832\n",
            "\n",
            "Tue Nov 04 12:08:02 AM 2025 AUC 0.927391651510742\n",
            "\n",
            "Tue Nov 04 12:10:07 AM 2025 AUC 0.927171349337348\n",
            "\n",
            "Tue Nov 04 12:11:29 AM 2025 AUC 0.925913242214629\n",
            "\n",
            "Tue Nov 04 12:12:48 AM 2025 AUC 0.926306903153657\n",
            "\n",
            "Tue Nov 04 12:14:45 AM 2025 AUC 0.928310747397686\n",
            "\n",
            "Tue Nov 04 12:15:14 AM 2025 AUC 0.92630270533795\n",
            "\n",
            "Tue Nov 04 12:16:15 AM 2025 AUC 0.927904087044835\n",
            "\n",
            "Tue Nov 04 12:17:28 AM 2025 AUC 0.929663266036314\n",
            "\n",
            "Tue Nov 04 12:17:56 AM 2025 AUC 0.925227874140098\n",
            "\n",
            "Tue Nov 04 12:19:38 AM 2025 AUC 0.926320052354651\n",
            "\n",
            "Tue Nov 04 12:20:42 AM 2025 AUC 0.927478144025812\n",
            "\n",
            "Tue Nov 04 12:21:04 AM 2025 AUC 0.923903900060825\n",
            "\n",
            "Tue Nov 04 12:23:15 AM 2025 AUC 0.926924845798852\n",
            "\n",
            "Tue Nov 04 12:25:02 AM 2025 AUC 0.926990020806855\n",
            "\n",
            "Tue Nov 04 12:26:17 AM 2025 AUC 0.927679519319022\n",
            "\n",
            "Tue Nov 04 12:26:46 AM 2025 AUC 0.927492417813375\n",
            "\n",
            "Tue Nov 04 12:29:55 AM 2025 AUC 0.927711469726929\n",
            "\n",
            "Tue Nov 04 12:30:09 AM 2025 AUC 0.926190280795422\n",
            "\n",
            "Tue Nov 04 12:31:45 AM 2025 AUC 0.925221721689295\n",
            "\n",
            "Tue Nov 04 12:33:34 AM 2025 AUC 0.927950681613785\n",
            "\n",
            "Tue Nov 04 12:36:04 AM 2025 AUC 0.929071183569996\n",
            "\n",
            "Tue Nov 04 12:36:22 AM 2025 AUC 0.92532222378643\n",
            "\n",
            "Tue Nov 04 12:39:51 AM 2025 AUC 0.922324569618109\n",
            "\n",
            "Tue Nov 04 12:40:38 AM 2025 AUC 0.924697149383704\n",
            "\n",
            "Tue Nov 04 12:42:45 AM 2025 AUC 0.924414487546098\n",
            "\n",
            "Tue Nov 04 12:43:25 AM 2025 AUC 0.926346554121547\n",
            "\n",
            "[mbo] 0: learning_rate=0.0735; num_leaves=227; min_data_in_leaf=1792; num_iterations=925; feature_fraction=0.8; bagging_fraction=0.626; lambda_l2=3.49; scale_pos_weight=133 : y = 0.925 : 86.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.076; num_leaves=372; min_data_in_leaf=1361; num_iterations=1025; feature_fraction=0.522; bagging_fraction=0.608; lambda_l2=7.02; scale_pos_weight=51.1 : y = 0.925 : 138.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0329; num_leaves=107; min_data_in_leaf=1424; num_iterations=384; feature_fraction=0.761; bagging_fraction=0.724; lambda_l2=2.57; scale_pos_weight=86.4 : y = 0.927 : 38.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0824; num_leaves=361; min_data_in_leaf=708; num_iterations=984; feature_fraction=0.595; bagging_fraction=0.699; lambda_l2=6.04; scale_pos_weight=26.5 : y = 0.926 : 130.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0667; num_leaves=246; min_data_in_leaf=989; num_iterations=676; feature_fraction=0.783; bagging_fraction=0.655; lambda_l2=0.0944; scale_pos_weight=92.7 : y = 0.926 : 75.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0619; num_leaves=386; min_data_in_leaf=1123; num_iterations=325; feature_fraction=0.61; bagging_fraction=0.816; lambda_l2=6.54; scale_pos_weight=126 : y = 0.928 : 37.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0524; num_leaves=465; min_data_in_leaf=1466; num_iterations=797; feature_fraction=0.407; bagging_fraction=0.778; lambda_l2=6.86; scale_pos_weight=70.9 : y = 0.927 : 99.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0399; num_leaves=324; min_data_in_leaf=1550; num_iterations=957; feature_fraction=0.496; bagging_fraction=0.588; lambda_l2=0.371; scale_pos_weight=155 : y = 0.927 : 124.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.078; num_leaves=149; min_data_in_leaf=889; num_iterations=731; feature_fraction=0.69; bagging_fraction=0.674; lambda_l2=5.79; scale_pos_weight=118 : y = 0.926 : 82.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0471; num_leaves=57; min_data_in_leaf=616; num_iterations=620; feature_fraction=0.354; bagging_fraction=0.621; lambda_l2=5.39; scale_pos_weight=47.9 : y = 0.926 : 79.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0102; num_leaves=180; min_data_in_leaf=312; num_iterations=787; feature_fraction=0.381; bagging_fraction=0.977; lambda_l2=7.36; scale_pos_weight=159 : y = 0.928 : 117.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0718; num_leaves=292; min_data_in_leaf=1140; num_iterations=270; feature_fraction=0.695; bagging_fraction=0.559; lambda_l2=7.51; scale_pos_weight=59.7 : y = 0.926 : 29.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0462; num_leaves=450; min_data_in_leaf=836; num_iterations=488; feature_fraction=0.316; bagging_fraction=0.792; lambda_l2=1.91; scale_pos_weight=124 : y = 0.928 : 61.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0147; num_leaves=95; min_data_in_leaf=503; num_iterations=563; feature_fraction=0.812; bagging_fraction=0.869; lambda_l2=8.91; scale_pos_weight=43.4 : y = 0.93 : 72.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0984; num_leaves=164; min_data_in_leaf=397; num_iterations=199; feature_fraction=0.326; bagging_fraction=0.747; lambda_l2=8.06; scale_pos_weight=110 : y = 0.925 : 28.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0516; num_leaves=470; min_data_in_leaf=46; num_iterations=452; feature_fraction=0.741; bagging_fraction=0.923; lambda_l2=2.44; scale_pos_weight=32.9 : y = 0.926 : 101.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0381; num_leaves=410; min_data_in_leaf=1014; num_iterations=592; feature_fraction=0.827; bagging_fraction=0.998; lambda_l2=1.27; scale_pos_weight=136 : y = 0.927 : 64.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0914; num_leaves=488; min_data_in_leaf=1859; num_iterations=231; feature_fraction=0.667; bagging_fraction=0.66; lambda_l2=3.17; scale_pos_weight=95.2 : y = 0.924 : 22.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0296; num_leaves=186; min_data_in_leaf=1894; num_iterations=1088; feature_fraction=0.419; bagging_fraction=0.798; lambda_l2=5.3; scale_pos_weight=113 : y = 0.927 : 130.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0639; num_leaves=271; min_data_in_leaf=1674; num_iterations=1138; feature_fraction=0.886; bagging_fraction=0.761; lambda_l2=4.11; scale_pos_weight=80.4 : y = 0.927 : 107.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0415; num_leaves=46; min_data_in_leaf=777; num_iterations=715; feature_fraction=0.635; bagging_fraction=0.955; lambda_l2=0.776; scale_pos_weight=76.5 : y = 0.928 : 75.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0587; num_leaves=123; min_data_in_leaf=1308; num_iterations=288; feature_fraction=0.648; bagging_fraction=0.944; lambda_l2=9.77; scale_pos_weight=104 : y = 0.927 : 29.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0219; num_leaves=406; min_data_in_leaf=199; num_iterations=1109; feature_fraction=0.849; bagging_fraction=0.848; lambda_l2=8.58; scale_pos_weight=64.3 : y = 0.928 : 188.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.056; num_leaves=204; min_data_in_leaf=1222; num_iterations=138; feature_fraction=0.868; bagging_fraction=0.524; lambda_l2=3.01; scale_pos_weight=139 : y = 0.926 : 14.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0855; num_leaves=315; min_data_in_leaf=1945; num_iterations=834; feature_fraction=0.368; bagging_fraction=0.882; lambda_l2=4.62; scale_pos_weight=22.2 : y = 0.925 : 95.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0303; num_leaves=279; min_data_in_leaf=97; num_iterations=540; feature_fraction=0.539; bagging_fraction=0.568; lambda_l2=9.38; scale_pos_weight=143 : y = 0.928 : 109.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0159; num_leaves=347; min_data_in_leaf=653; num_iterations=1045; feature_fraction=0.455; bagging_fraction=0.505; lambda_l2=3.88; scale_pos_weight=55.9 : y = 0.929 : 150.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0241; num_leaves=227; min_data_in_leaf=377; num_iterations=109; feature_fraction=0.446; bagging_fraction=0.838; lambda_l2=4.71; scale_pos_weight=38 : y = 0.925 : 17.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0869; num_leaves=430; min_data_in_leaf=176; num_iterations=1187; feature_fraction=0.562; bagging_fraction=0.894; lambda_l2=1.2; scale_pos_weight=84.6 : y = 0.922 : 208.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0967; num_leaves=68; min_data_in_leaf=1589; num_iterations=354; feature_fraction=0.487; bagging_fraction=0.919; lambda_l2=1.71; scale_pos_weight=149 : y = 0.925 : 46.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0939; num_leaves=83; min_data_in_leaf=555; num_iterations=882; feature_fraction=0.566; bagging_fraction=0.535; lambda_l2=9.37; scale_pos_weight=34.8 : y = 0.924 : 127.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.02; num_leaves=500; min_data_in_leaf=1741; num_iterations=426; feature_fraction=0.723; bagging_fraction=0.707; lambda_l2=8.31; scale_pos_weight=100 : y = 0.926 : 39.1 secs : initdesign\n",
            "\n",
            "Saved the current state after iteration 1 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 12:45:39 AM 2025 AUC 0.928415251970725\n",
            "\n",
            "[mbo] 1: learning_rate=0.0145; num_leaves=192; min_data_in_leaf=434; num_iterations=989; feature_fraction=0.742; bagging_fraction=0.703; lambda_l2=8.22; scale_pos_weight=57.7 : y = 0.928 : 134.2 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 12:47:03 AM 2025 AUC 0.928367039773208\n",
            "\n",
            "[mbo] 2: learning_rate=0.0121; num_leaves=75; min_data_in_leaf=633; num_iterations=680; feature_fraction=0.835; bagging_fraction=0.925; lambda_l2=8.06; scale_pos_weight=84.4 : y = 0.928 : 83.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 12:48:33 AM 2025 AUC 0.929125901720972\n",
            "\n",
            "[mbo] 3: learning_rate=0.0151; num_leaves=110; min_data_in_leaf=463; num_iterations=591; feature_fraction=0.427; bagging_fraction=0.762; lambda_l2=8.74; scale_pos_weight=38.6 : y = 0.929 : 89.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 12:49:42 AM 2025 AUC 0.928259365485476\n",
            "\n",
            "[mbo] 4: learning_rate=0.0145; num_leaves=102; min_data_in_leaf=298; num_iterations=511; feature_fraction=0.786; bagging_fraction=0.892; lambda_l2=9.54; scale_pos_weight=50 : y = 0.928 : 69.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 12:50:48 AM 2025 AUC 0.928104286689326\n",
            "\n",
            "[mbo] 5: learning_rate=0.0222; num_leaves=75; min_data_in_leaf=578; num_iterations=522; feature_fraction=0.822; bagging_fraction=0.742; lambda_l2=8.89; scale_pos_weight=52.3 : y = 0.928 : 64.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 12:52:48 AM 2025 AUC 0.929727195303003\n",
            "\n",
            "[mbo] 6: learning_rate=0.0142; num_leaves=332; min_data_in_leaf=547; num_iterations=936; feature_fraction=0.64; bagging_fraction=0.932; lambda_l2=8.91; scale_pos_weight=64 : y = 0.93 : 120.0 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 12:54:29 AM 2025 AUC 0.928385827727906\n",
            "\n",
            "[mbo] 7: learning_rate=0.0146; num_leaves=361; min_data_in_leaf=550; num_iterations=749; feature_fraction=0.802; bagging_fraction=0.83; lambda_l2=7.94; scale_pos_weight=41.4 : y = 0.928 : 100.2 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 8 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 12:55:55 AM 2025 AUC 0.93032984063968\n",
            "\n",
            "[mbo] 8: learning_rate=0.0131; num_leaves=66; min_data_in_leaf=619; num_iterations=664; feature_fraction=0.612; bagging_fraction=0.925; lambda_l2=7.11; scale_pos_weight=40.7 : y = 0.93 : 85.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 12:58:25 AM 2025 AUC 0.929487440641834\n",
            "\n",
            "[mbo] 9: learning_rate=0.0137; num_leaves=301; min_data_in_leaf=826; num_iterations=1026; feature_fraction=0.507; bagging_fraction=0.963; lambda_l2=3.93; scale_pos_weight=63.1 : y = 0.929 : 149.7 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 12:59:47 AM 2025 AUC 0.930262499669259\n",
            "\n",
            "[mbo] 10: learning_rate=0.0113; num_leaves=44; min_data_in_leaf=783; num_iterations=650; feature_fraction=0.591; bagging_fraction=0.898; lambda_l2=9.2; scale_pos_weight=42.4 : y = 0.93 : 81.7 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:00:55 AM 2025 AUC 0.928664289998758\n",
            "\n",
            "[mbo] 11: learning_rate=0.0132; num_leaves=54; min_data_in_leaf=1159; num_iterations=645; feature_fraction=0.8; bagging_fraction=0.928; lambda_l2=7.21; scale_pos_weight=34.3 : y = 0.929 : 67.2 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:03:09 AM 2025 AUC 0.928730095488331\n",
            "\n",
            "[mbo] 12: learning_rate=0.0143; num_leaves=145; min_data_in_leaf=642; num_iterations=901; feature_fraction=0.479; bagging_fraction=0.999; lambda_l2=9.97; scale_pos_weight=51.3 : y = 0.929 : 134.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:04:25 AM 2025 AUC 0.929649088746179\n",
            "\n",
            "[mbo] 13: learning_rate=0.0142; num_leaves=115; min_data_in_leaf=756; num_iterations=592; feature_fraction=0.604; bagging_fraction=0.708; lambda_l2=8.46; scale_pos_weight=50.8 : y = 0.93 : 75.2 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:06:17 AM 2025 AUC 0.928876027016535\n",
            "\n",
            "[mbo] 14: learning_rate=0.0118; num_leaves=367; min_data_in_leaf=318; num_iterations=665; feature_fraction=0.565; bagging_fraction=0.96; lambda_l2=8.22; scale_pos_weight=50.2 : y = 0.929 : 111.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 15 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 01:07:13 AM 2025 AUC 0.927547910186069\n",
            "\n",
            "[mbo] 15: learning_rate=0.01; num_leaves=86; min_data_in_leaf=553; num_iterations=440; feature_fraction=0.633; bagging_fraction=0.874; lambda_l2=7.71; scale_pos_weight=42.9 : y = 0.928 : 56.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:08:25 AM 2025 AUC 0.928290713548881\n",
            "\n",
            "[mbo] 16: learning_rate=0.0144; num_leaves=39; min_data_in_leaf=60; num_iterations=615; feature_fraction=0.594; bagging_fraction=0.989; lambda_l2=7.16; scale_pos_weight=68.3 : y = 0.928 : 70.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:09:53 AM 2025 AUC 0.929635736451782\n",
            "\n",
            "[mbo] 17: learning_rate=0.0133; num_leaves=96; min_data_in_leaf=683; num_iterations=734; feature_fraction=0.652; bagging_fraction=0.85; lambda_l2=8.8; scale_pos_weight=33.9 : y = 0.93 : 87.6 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:12:11 AM 2025 AUC 0.928221414942072\n",
            "\n",
            "[mbo] 18: learning_rate=0.0151; num_leaves=452; min_data_in_leaf=745; num_iterations=939; feature_fraction=0.552; bagging_fraction=0.741; lambda_l2=3.99; scale_pos_weight=81.6 : y = 0.928 : 137.8 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:13:25 AM 2025 AUC 0.92908230032626\n",
            "\n",
            "[mbo] 19: learning_rate=0.0137; num_leaves=44; min_data_in_leaf=557; num_iterations=683; feature_fraction=0.628; bagging_fraction=0.71; lambda_l2=1.58; scale_pos_weight=43.7 : y = 0.929 : 73.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:14:38 AM 2025 AUC 0.928599362653923\n",
            "\n",
            "[mbo] 20: learning_rate=0.013; num_leaves=62; min_data_in_leaf=667; num_iterations=632; feature_fraction=0.757; bagging_fraction=0.897; lambda_l2=8.8; scale_pos_weight=40.7 : y = 0.929 : 73.2 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:16:10 AM 2025 AUC 0.928720471198336\n",
            "\n",
            "[mbo] 21: learning_rate=0.0128; num_leaves=73; min_data_in_leaf=1172; num_iterations=683; feature_fraction=0.556; bagging_fraction=0.896; lambda_l2=6.11; scale_pos_weight=59.6 : y = 0.929 : 91.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:18:12 AM 2025 AUC 0.928916710347623\n",
            "\n",
            "[mbo] 22: learning_rate=0.0128; num_leaves=220; min_data_in_leaf=1075; num_iterations=1019; feature_fraction=0.604; bagging_fraction=0.921; lambda_l2=8.52; scale_pos_weight=40.4 : y = 0.929 : 121.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 23 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 01:19:52 AM 2025 AUC 0.928692968493733\n",
            "\n",
            "[mbo] 23: learning_rate=0.0124; num_leaves=140; min_data_in_leaf=581; num_iterations=681; feature_fraction=0.581; bagging_fraction=0.956; lambda_l2=7.35; scale_pos_weight=98 : y = 0.929 : 99.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:21:26 AM 2025 AUC 0.928417945209783\n",
            "\n",
            "[mbo] 24: learning_rate=0.0115; num_leaves=115; min_data_in_leaf=714; num_iterations=667; feature_fraction=0.579; bagging_fraction=0.932; lambda_l2=8.34; scale_pos_weight=21.1 : y = 0.928 : 93.7 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:22:48 AM 2025 AUC 0.928399924800117\n",
            "\n",
            "[mbo] 25: learning_rate=0.0158; num_leaves=66; min_data_in_leaf=753; num_iterations=692; feature_fraction=0.856; bagging_fraction=0.943; lambda_l2=8.25; scale_pos_weight=40.5 : y = 0.928 : 81.7 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:24:26 AM 2025 AUC 0.928671743917951\n",
            "\n",
            "[mbo] 26: learning_rate=0.0147; num_leaves=101; min_data_in_leaf=631; num_iterations=721; feature_fraction=0.594; bagging_fraction=0.887; lambda_l2=7.24; scale_pos_weight=49.5 : y = 0.929 : 97.3 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:25:35 AM 2025 AUC 0.92829823983607\n",
            "\n",
            "[mbo] 27: learning_rate=0.0146; num_leaves=153; min_data_in_leaf=1202; num_iterations=580; feature_fraction=0.599; bagging_fraction=0.816; lambda_l2=3.69; scale_pos_weight=38.9 : y = 0.928 : 68.6 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:27:17 AM 2025 AUC 0.928159200918935\n",
            "\n",
            "[mbo] 28: learning_rate=0.0125; num_leaves=278; min_data_in_leaf=671; num_iterations=804; feature_fraction=0.619; bagging_fraction=0.902; lambda_l2=5.74; scale_pos_weight=63.4 : y = 0.928 : 101.8 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:28:37 AM 2025 AUC 0.929176212211059\n",
            "\n",
            "[mbo] 29: learning_rate=0.0114; num_leaves=238; min_data_in_leaf=706; num_iterations=643; feature_fraction=0.628; bagging_fraction=0.85; lambda_l2=9.1; scale_pos_weight=76.3 : y = 0.929 : 79.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 30 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 01:30:22 AM 2025 AUC 0.929072856243949\n",
            "\n",
            "[mbo] 30: learning_rate=0.0134; num_leaves=486; min_data_in_leaf=549; num_iterations=735; feature_fraction=0.387; bagging_fraction=0.929; lambda_l2=7.01; scale_pos_weight=33 : y = 0.929 : 104.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:31:51 AM 2025 AUC 0.92927176445815\n",
            "\n",
            "[mbo] 31: learning_rate=0.0138; num_leaves=70; min_data_in_leaf=572; num_iterations=636; feature_fraction=0.422; bagging_fraction=0.927; lambda_l2=7.89; scale_pos_weight=89.5 : y = 0.929 : 88.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:32:56 AM 2025 AUC 0.928466771211527\n",
            "\n",
            "[mbo] 32: learning_rate=0.0137; num_leaves=36; min_data_in_leaf=869; num_iterations=614; feature_fraction=0.627; bagging_fraction=0.864; lambda_l2=4.26; scale_pos_weight=71.7 : y = 0.928 : 64.3 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:34:26 AM 2025 AUC 0.929083507209847\n",
            "\n",
            "[mbo] 33: learning_rate=0.0113; num_leaves=439; min_data_in_leaf=785; num_iterations=664; feature_fraction=0.425; bagging_fraction=0.702; lambda_l2=9.69; scale_pos_weight=59.3 : y = 0.929 : 90.0 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:37:11 AM 2025 AUC 0.929400172915352\n",
            "\n",
            "[mbo] 34: learning_rate=0.0135; num_leaves=414; min_data_in_leaf=286; num_iterations=1072; feature_fraction=0.648; bagging_fraction=0.869; lambda_l2=9.95; scale_pos_weight=68.7 : y = 0.929 : 164.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:38:26 AM 2025 AUC 0.929667257636659\n",
            "\n",
            "[mbo] 35: learning_rate=0.0123; num_leaves=43; min_data_in_leaf=925; num_iterations=648; feature_fraction=0.609; bagging_fraction=0.936; lambda_l2=9.07; scale_pos_weight=35.7 : y = 0.93 : 74.4 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:39:47 AM 2025 AUC 0.927568181118125\n",
            "\n",
            "[mbo] 36: learning_rate=0.0129; num_leaves=72; min_data_in_leaf=921; num_iterations=657; feature_fraction=0.318; bagging_fraction=0.633; lambda_l2=7.86; scale_pos_weight=45.5 : y = 0.928 : 80.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 37 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 01:42:29 AM 2025 AUC 0.927922617936127\n",
            "\n",
            "[mbo] 37: learning_rate=0.0136; num_leaves=341; min_data_in_leaf=635; num_iterations=1064; feature_fraction=0.537; bagging_fraction=0.876; lambda_l2=6.11; scale_pos_weight=136 : y = 0.928 : 161.7 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:44:51 AM 2025 AUC 0.929412448349218\n",
            "\n",
            "[mbo] 38: learning_rate=0.0144; num_leaves=376; min_data_in_leaf=492; num_iterations=973; feature_fraction=0.592; bagging_fraction=0.923; lambda_l2=8.99; scale_pos_weight=31.3 : y = 0.929 : 140.7 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:46:22 AM 2025 AUC 0.929556836431068\n",
            "\n",
            "[mbo] 39: learning_rate=0.0116; num_leaves=33; min_data_in_leaf=532; num_iterations=694; feature_fraction=0.499; bagging_fraction=0.926; lambda_l2=2.51; scale_pos_weight=46.8 : y = 0.93 : 91.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:47:22 AM 2025 AUC 0.927438143616141\n",
            "\n",
            "[mbo] 40: learning_rate=0.0149; num_leaves=94; min_data_in_leaf=1278; num_iterations=587; feature_fraction=0.828; bagging_fraction=0.523; lambda_l2=7.27; scale_pos_weight=52.4 : y = 0.927 : 59.7 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:49:25 AM 2025 AUC 0.928445086468734\n",
            "\n",
            "[mbo] 41: learning_rate=0.0113; num_leaves=44; min_data_in_leaf=1138; num_iterations=895; feature_fraction=0.542; bagging_fraction=0.864; lambda_l2=9.25; scale_pos_weight=109 : y = 0.928 : 121.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:51:02 AM 2025 AUC 0.929376148757497\n",
            "\n",
            "[mbo] 42: learning_rate=0.0104; num_leaves=58; min_data_in_leaf=583; num_iterations=672; feature_fraction=0.555; bagging_fraction=0.839; lambda_l2=6.21; scale_pos_weight=40.3 : y = 0.929 : 96.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 43 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 01:52:39 AM 2025 AUC 0.928703247357603\n",
            "\n",
            "[mbo] 43: learning_rate=0.0117; num_leaves=125; min_data_in_leaf=679; num_iterations=650; feature_fraction=0.545; bagging_fraction=0.918; lambda_l2=9.68; scale_pos_weight=45.3 : y = 0.929 : 96.8 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:54:58 AM 2025 AUC 0.929609734240398\n",
            "\n",
            "[mbo] 44: learning_rate=0.0134; num_leaves=132; min_data_in_leaf=515; num_iterations=900; feature_fraction=0.477; bagging_fraction=0.792; lambda_l2=3.07; scale_pos_weight=48.4 : y = 0.93 : 139.0 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:57:02 AM 2025 AUC 0.929309527994069\n",
            "\n",
            "[mbo] 45: learning_rate=0.0132; num_leaves=136; min_data_in_leaf=126; num_iterations=703; feature_fraction=0.517; bagging_fraction=0.672; lambda_l2=9.49; scale_pos_weight=54.2 : y = 0.929 : 122.9 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 01:59:26 AM 2025 AUC 0.928618835431237\n",
            "\n",
            "[mbo] 46: learning_rate=0.0137; num_leaves=281; min_data_in_leaf=429; num_iterations=929; feature_fraction=0.449; bagging_fraction=0.729; lambda_l2=6.64; scale_pos_weight=57.9 : y = 0.929 : 143.1 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:01:22 AM 2025 AUC 0.928598447489513\n",
            "\n",
            "[mbo] 47: learning_rate=0.0118; num_leaves=227; min_data_in_leaf=816; num_iterations=854; feature_fraction=0.607; bagging_fraction=0.839; lambda_l2=7.44; scale_pos_weight=58.3 : y = 0.929 : 115.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 48 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Nov 04 02:03:13 AM 2025 AUC 0.928716402977041\n",
            "\n",
            "[mbo] 48: learning_rate=0.0113; num_leaves=116; min_data_in_leaf=372; num_iterations=665; feature_fraction=0.474; bagging_fraction=0.592; lambda_l2=6.03; scale_pos_weight=63.9 : y = 0.929 : 110.5 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:05:43 AM 2025 AUC 0.92940868207861\n",
            "\n",
            "[mbo] 49: learning_rate=0.0144; num_leaves=333; min_data_in_leaf=723; num_iterations=1156; feature_fraction=0.633; bagging_fraction=0.835; lambda_l2=5.55; scale_pos_weight=52 : y = 0.929 : 149.7 secs : infill_ei\n",
            "\n",
            "Tue Nov 04 02:07:17 AM 2025 AUC 0.929169111907116\n",
            "\n",
            "[mbo] 50: learning_rate=0.0134; num_leaves=115; min_data_in_leaf=524; num_iterations=598; feature_fraction=0.561; bagging_fraction=0.894; lambda_l2=8.6; scale_pos_weight=28.6 : y = 0.929 : 92.9 secs : infill_ei\n",
            "\n",
            "Saved the final state in the file bayesiana.RDATA\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "colnames( tb_bayesiana)"
      ],
      "metadata": {
        "id": "ssk5nnMk6INK",
        "outputId": "5b354568-1c87-484a-e54d-b85bb34d06e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'learning_rate'</li><li>'num_leaves'</li><li>'min_data_in_leaf'</li><li>'num_iterations'</li><li>'feature_fraction'</li><li>'bagging_fraction'</li><li>'lambda_l2'</li><li>'scale_pos_weight'</li><li>'y'</li><li>'dob'</li><li>'eol'</li><li>'error.message'</li><li>'exec.time'</li><li>'ei'</li><li>'error.model'</li><li>'train.time'</li><li>'prop.type'</li><li>'propose.time'</li><li>'se'</li><li>'mean'</li></ol>\n"
            ],
            "text/markdown": "1. 'learning_rate'\n2. 'num_leaves'\n3. 'min_data_in_leaf'\n4. 'num_iterations'\n5. 'feature_fraction'\n6. 'bagging_fraction'\n7. 'lambda_l2'\n8. 'scale_pos_weight'\n9. 'y'\n10. 'dob'\n11. 'eol'\n12. 'error.message'\n13. 'exec.time'\n14. 'ei'\n15. 'error.model'\n16. 'train.time'\n17. 'prop.type'\n18. 'propose.time'\n19. 'se'\n20. 'mean'\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 'learning\\_rate'\n\\item 'num\\_leaves'\n\\item 'min\\_data\\_in\\_leaf'\n\\item 'num\\_iterations'\n\\item 'feature\\_fraction'\n\\item 'bagging\\_fraction'\n\\item 'lambda\\_l2'\n\\item 'scale\\_pos\\_weight'\n\\item 'y'\n\\item 'dob'\n\\item 'eol'\n\\item 'error.message'\n\\item 'exec.time'\n\\item 'ei'\n\\item 'error.model'\n\\item 'train.time'\n\\item 'prop.type'\n\\item 'propose.time'\n\\item 'se'\n\\item 'mean'\n\\end{enumerate*}\n",
            "text/plain": [
              " [1] \"learning_rate\"    \"num_leaves\"       \"min_data_in_leaf\" \"num_iterations\"  \n",
              " [5] \"feature_fraction\" \"bagging_fraction\" \"lambda_l2\"        \"scale_pos_weight\"\n",
              " [9] \"y\"                \"dob\"              \"eol\"              \"error.message\"   \n",
              "[13] \"exec.time\"        \"ei\"               \"error.model\"      \"train.time\"      \n",
              "[17] \"prop.type\"        \"propose.time\"     \"se\"               \"mean\"            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# almaceno los resultados de la Bayesian Optimization\n",
        "# y capturo los mejores hiperparametros encontrados\n",
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "\n",
        "tb_bayesiana[, iter := .I]\n",
        "\n",
        "# ordeno en forma descendente por AUC = y\n",
        "setorder(tb_bayesiana, -y)\n",
        "\n",
        "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
        "fwrite( tb_bayesiana,\n",
        "  file= \"BO_log.txt\",\n",
        "  sep= \"\\t\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "u4zq-vknhjGc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "k_top <- 10\n",
        "semillas <- c(310019, 320009, 330017, 340007, 350029)\n",
        "lambda_riesgo <- 0.2\n",
        "\n",
        "\n",
        "# Columnas de hiperparámetros detectadas automáticamente\n",
        "cols_hp <- setdiff(\n",
        "  colnames(tb_bayesiana),\n",
        "  c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
        "    \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")\n",
        ")\n",
        "\n",
        "top_hp <- tb_bayesiana[1:k_top, ..cols_hp]\n",
        "\n",
        "resultados <- list()\n",
        "\n",
        "for(i in 1:nrow(top_hp)) {\n",
        "  hp <- as.list(top_hp[i])\n",
        "  AUCs <- c()\n",
        "\n",
        "  for(seed in semillas) {\n",
        "    cat(\"\\n>>> Modelo\", i, \"Semilla\", seed, \"\\n\")\n",
        "\n",
        "    # === Reproducir tu pipeline exacto ===\n",
        "    set.seed(seed, kind=\"L'Ecuyer-CMRG\")\n",
        "\n",
        "    dataset_train <- dataset[foto_mes == 202107]\n",
        "    dataset_train[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\",\"BAJA+2\"),1L,0L)]\n",
        "    dataset_train[, azar := runif(.N)]\n",
        "    dataset_train[, training := 0L]\n",
        "\n",
        "    dataset_train[\n",
        "      (azar <= PARAM$trainingstrategy$undersampling |\n",
        "       clase_ternaria %in% c(\"BAJA+1\",\"BAJA+2\")),\n",
        "      training := 1L\n",
        "    ]\n",
        "\n",
        "    campos_buenos <- setdiff(\n",
        "      names(dataset_train),\n",
        "      c(\"clase_ternaria\",\"clase01\",\"azar\",\"training\")\n",
        "    )\n",
        "\n",
        "    dtrain <- lgb.Dataset(\n",
        "      data = data.matrix(dataset_train[training==1, ..campos_buenos]),\n",
        "      label = dataset_train[training==1, clase01],\n",
        "      free_raw_data = FALSE\n",
        "    )\n",
        "\n",
        "    param <- modifyList(PARAM$lgbm$param_fijos, hp)\n",
        "    param$min_data_in_leaf <- round(param$min_data_in_leaf / PARAM$trainingstrategy$undersampling)\n",
        "\n",
        "    modelocv <- lgb.cv(\n",
        "      data = dtrain,\n",
        "      nfold = PARAM$hyperparametertuning$xval_folds,\n",
        "      stratified = TRUE,\n",
        "      param = param\n",
        "    )\n",
        "\n",
        "    AUC <- modelocv$best_score\n",
        "    AUCs <- c(AUCs, AUC)\n",
        "\n",
        "    rm(modelocv); gc()\n",
        "  }\n",
        "\n",
        "  resultados[[i]] <- data.table(\n",
        "    modelo = i,\n",
        "    mean_auc = mean(AUCs),\n",
        "    sd_auc = sd(AUCs),\n",
        "    score_rob = mean(AUCs) - lambda_riesgo * sd(AUCs),\n",
        "    hiperparametros = list(hp),\n",
        "    AUCs = list(AUCs)\n",
        "  )\n",
        "}\n",
        "\n",
        "tb_res <- rbindlist(resultados)\n",
        "setorder(tb_res, -score_rob)\n",
        "\n",
        "cat(\"\\n### RESULTADOS FINALES ###\\n\")\n",
        "print(tb_res)\n",
        "\n",
        "mejor <- tb_res[1]\n",
        "PARAM$out$lgbm$mejores_hiperparametros <- unlist(mejor$hiperparametros)\n",
        "\n",
        "cat(\"\\n✅ Seleccionado (AUC robusto):\\n\")\n",
        "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
        "\n",
        "cat(\"\\nMedia AUC:\", mejor$mean_auc,\n",
        "    \"\\nDesvío:\", mejor$sd_auc,\n",
        "    \"\\nScore robusto:\", mejor$score_rob, \"\\n\")"
      ],
      "metadata": {
        "id": "ChL6ZL10JE05",
        "outputId": "a2538e85-19ad-4798-dead-3e445eb7a64e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Modelo 1 Semilla 310019 \n",
            "\n",
            ">>> Modelo 1 Semilla 320009 \n",
            "\n",
            ">>> Modelo 1 Semilla 330017 \n",
            "\n",
            ">>> Modelo 1 Semilla 340007 \n",
            "\n",
            ">>> Modelo 1 Semilla 350029 \n",
            "\n",
            ">>> Modelo 2 Semilla 310019 \n",
            "\n",
            ">>> Modelo 2 Semilla 320009 \n",
            "\n",
            ">>> Modelo 2 Semilla 330017 \n",
            "\n",
            ">>> Modelo 2 Semilla 340007 \n",
            "\n",
            ">>> Modelo 2 Semilla 350029 \n",
            "\n",
            ">>> Modelo 3 Semilla 310019 \n",
            "\n",
            ">>> Modelo 3 Semilla 320009 \n",
            "\n",
            ">>> Modelo 3 Semilla 330017 \n",
            "\n",
            ">>> Modelo 3 Semilla 340007 \n",
            "\n",
            ">>> Modelo 3 Semilla 350029 \n",
            "\n",
            ">>> Modelo 4 Semilla 310019 \n",
            "\n",
            ">>> Modelo 4 Semilla 320009 \n",
            "\n",
            ">>> Modelo 4 Semilla 330017 \n",
            "\n",
            ">>> Modelo 4 Semilla 340007 \n",
            "\n",
            ">>> Modelo 4 Semilla 350029 \n",
            "\n",
            ">>> Modelo 5 Semilla 310019 \n",
            "\n",
            ">>> Modelo 5 Semilla 320009 \n",
            "\n",
            ">>> Modelo 5 Semilla 330017 \n",
            "\n",
            ">>> Modelo 5 Semilla 340007 \n",
            "\n",
            ">>> Modelo 5 Semilla 350029 \n",
            "\n",
            ">>> Modelo 6 Semilla 310019 \n",
            "\n",
            ">>> Modelo 6 Semilla 320009 \n",
            "\n",
            ">>> Modelo 6 Semilla 330017 \n",
            "\n",
            ">>> Modelo 6 Semilla 340007 \n",
            "\n",
            ">>> Modelo 6 Semilla 350029 \n",
            "\n",
            ">>> Modelo 7 Semilla 310019 \n",
            "\n",
            ">>> Modelo 7 Semilla 320009 \n",
            "\n",
            ">>> Modelo 7 Semilla 330017 \n",
            "\n",
            ">>> Modelo 7 Semilla 340007 \n",
            "\n",
            ">>> Modelo 7 Semilla 350029 \n",
            "\n",
            ">>> Modelo 8 Semilla 310019 \n",
            "\n",
            ">>> Modelo 8 Semilla 320009 \n",
            "\n",
            ">>> Modelo 8 Semilla 330017 \n",
            "\n",
            ">>> Modelo 8 Semilla 340007 \n",
            "\n",
            ">>> Modelo 8 Semilla 350029 \n",
            "\n",
            ">>> Modelo 9 Semilla 310019 \n",
            "\n",
            ">>> Modelo 9 Semilla 320009 \n",
            "\n",
            ">>> Modelo 9 Semilla 330017 \n",
            "\n",
            ">>> Modelo 9 Semilla 340007 \n",
            "\n",
            ">>> Modelo 9 Semilla 350029 \n",
            "\n",
            ">>> Modelo 10 Semilla 310019 \n",
            "\n",
            ">>> Modelo 10 Semilla 320009 \n",
            "\n",
            ">>> Modelo 10 Semilla 330017 \n",
            "\n",
            ">>> Modelo 10 Semilla 340007 \n",
            "\n",
            ">>> Modelo 10 Semilla 350029 \n",
            "\n",
            "### RESULTADOS FINALES ###\n",
            "    modelo  mean_auc       sd_auc score_rob hiperparametros\n",
            "     <int>     <num>        <num>     <num>          <list>\n",
            " 1:      8 0.9290634 0.0008902794 0.9288853       <list[8]>\n",
            " 2:      1 0.9288842 0.0008682348 0.9287106       <list[8]>\n",
            " 3:      3 0.9288486 0.0008075584 0.9286871       <list[8]>\n",
            " 4:      7 0.9286304 0.0008869897 0.9284530       <list[8]>\n",
            " 5:      9 0.9285953 0.0007697754 0.9284413       <list[8]>\n",
            " 6:      5 0.9285749 0.0009071779 0.9283935       <list[8]>\n",
            " 7:     10 0.9283118 0.0007318865 0.9281655       <list[8]>\n",
            " 8:      2 0.9282117 0.0008373791 0.9280443       <list[8]>\n",
            " 9:      6 0.9281813 0.0006926104 0.9280428       <list[8]>\n",
            "10:      4 0.9281179 0.0006739076 0.9279831       <list[8]>\n",
            "                                                 AUCs\n",
            "                                               <list>\n",
            " 1: 0.9283871,0.9284199,0.9290629,0.9305683,0.9288788\n",
            " 2: 0.9286727,0.9280683,0.9290468,0.9302925,0.9283409\n",
            " 3: 0.9287528,0.9282528,0.9286522,0.9302444,0.9283409\n",
            " 4: 0.9280116,0.9284203,0.9285981,0.9301445,0.9279774\n",
            " 5: 0.9280602,0.9283312,0.9285506,0.9299272,0.9281073\n",
            " 6: 0.9280209,0.9279689,0.9281700,0.9301414,0.9285734\n",
            " 7: 0.9278419,0.9279937,0.9282907,0.9295804,0.9278526\n",
            " 8: 0.9279337,0.9279312,0.9278582,0.9296944,0.9276412\n",
            " 9: 0.9276660,0.9279108,0.9281231,0.9293845,0.9278220\n",
            "10: 0.9275375,0.9277760,0.9280782,0.9292692,0.9279286\n",
            "\n",
            "✅ Seleccionado (AUC robusto):\n",
            "   learning_rate       num_leaves min_data_in_leaf   num_iterations \n",
            "      0.01336094     132.00000000     515.00000000     900.00000000 \n",
            "feature_fraction bagging_fraction        lambda_l2 scale_pos_weight \n",
            "      0.47700229       0.79220920       3.07317078      48.36966808 \n",
            "\n",
            "Media AUC: 0.9290634 \n",
            "Desvío: 0.0008902794 \n",
            "Score robusto: 0.9288853 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ],
      "metadata": {
        "id": "E8v2eA427N8e"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
        "print(PARAM$out$lgbm$y)"
      ],
      "metadata": {
        "id": "iBTWexVU7PGC",
        "outputId": "f6dc6aa6-9cdb-434a-9bb1-490d3120071c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   learning_rate       num_leaves min_data_in_leaf   num_iterations \n",
            "      0.01336094     132.00000000     515.00000000     900.00000000 \n",
            "feature_fraction bagging_fraction        lambda_l2 scale_pos_weight \n",
            "      0.47700229       0.79220920       3.07317078      48.36966808 \n",
            "NULL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3  Produccion"
      ],
      "metadata": {
        "id": "TKsVZmAnhwX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Training\n",
        "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
      ],
      "metadata": {
        "id": "RQ_C33Tr5B_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento <- paste0(\"exp\", PARAM$experimento)\n",
        "dir.create(experimento, showWarnings= FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
      ],
      "metadata": {
        "id": "eDqfyA14hzwv"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Final Training Dataset\n",
        "\n",
        "Aqui esta la gran decision de en qué meses hago el Final Training\n",
        "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
      ],
      "metadata": {
        "id": "8qFmFivf5Iet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clase01\n",
        "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]"
      ],
      "metadata": {
        "id": "lg5WVZncvc7H"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train <- dataset[foto_mes %in% c(202107)]"
      ],
      "metadata": {
        "id": "yc9QzXREv0xf"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[, clase01]\n",
        ")"
      ],
      "metadata": {
        "id": "thjdqEBLuvNt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Final Training Hyperparameters"
      ],
      "metadata": {
        "id": "VNUa-WSz5Oqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
        "  PARAM$out$lgbm$mejores_hiperparametros)\n",
        "\n",
        "param_final"
      ],
      "metadata": {
        "id": "FgCcvBfEwImu",
        "outputId": "b67c8a6b-cb96-4bf3-f8a1-d3e57ff1463c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "Error in modifyList(PARAM$lgbm$param_fijos, PARAM$out$lgbm$mejores_hiperparametros): is.list(val) is not TRUE\n",
          "traceback": [
            "Error in modifyList(PARAM$lgbm$param_fijos, PARAM$out$lgbm$mejores_hiperparametros): is.list(val) is not TRUE\nTraceback:\n",
            "1. stopifnot(is.list(x), is.list(val))",
            "2. stop(simpleError(msg, call = if (p <- sys.parent(1L)) sys.call(p)))"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training\n",
        "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
      ],
      "metadata": {
        "id": "TZIYn4l95TBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
        "\n",
        "param_normalizado <- copy(param_final)\n",
        "param_normalizado$min_data_in_leaf <-  round(param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling)"
      ],
      "metadata": {
        "id": "vPLsd4mMRe4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # entreno LightGBM\n",
        "\n",
        "  modelo_final <- lgb.train(\n",
        "    data= dtrain,\n",
        "    param= param_normalizado\n",
        "  )"
      ],
      "metadata": {
        "id": "WRI_-taRwOXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ahora imprimo la importancia de variables\n",
        "\n",
        "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
        "archivo_importancia <- \"impo.txt\"\n",
        "\n",
        "fwrite(tb_importancia,\n",
        "  file= archivo_importancia,\n",
        "  sep= \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "_bkhnCvj0g3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
        "\n",
        "lgb.save(modelo_final, \"modelo.txt\" )"
      ],
      "metadata": {
        "id": "lZ3sLmbh0kFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scoring"
      ],
      "metadata": {
        "id": "VEtp2--t5Ymg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplico el modelo final a los datos del futuro"
      ],
      "metadata": {
        "id": "hI5008Mj5ZdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# aplico el modelo a los datos sin clase\n",
        "dfuture <- dataset[foto_mes == 202109]\n",
        "\n",
        "# aplico el modelo a los datos nuevos\n",
        "prediccion <- predict(\n",
        "  modelo_final,\n",
        "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
        ")"
      ],
      "metadata": {
        "id": "PimBY3N_0ryP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tabla Prediccion"
      ],
      "metadata": {
        "id": "D26rNRh55gpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tabla de prediccion\n",
        "\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
        "tb_prediccion[, prob := prediccion ]\n",
        "\n",
        "# grabo las probabilidad del modelo\n",
        "fwrite(tb_prediccion,\n",
        "  file= \"prediccion.txt\",\n",
        "  sep= \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "RJwg7LHd11yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaggle Competition Submit"
      ],
      "metadata": {
        "id": "jOt4eG_55ltv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# genero archivos con los  \"envios\" mejores\n",
        "# suba TODOS los archivos a Kaggle\n",
        "\n",
        "# ordeno por probabilidad descendente\n",
        "setorder(tb_prediccion, -prob)\n",
        "\n",
        "dir.create(\"kaggle\")\n",
        "\n",
        "for (envios in PARAM$kaggle$cortes) {\n",
        "\n",
        "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
        "  tb_prediccion[1:envios, Predicted := 1L] # marclo los primeros\n",
        "\n",
        "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
        "\n",
        "  # grabo el archivo\n",
        "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "    file= archivo_kaggle,\n",
        "    sep= \",\"\n",
        "  )\n",
        "\n",
        "  # subida a Kaggle, armo la linea de comando\n",
        "  comando <- \"kaggle competitions submit\"\n",
        "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
        "  arch <- paste( \"-f\", archivo_kaggle)\n",
        "\n",
        "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
        "  \"  semilla=\", PARAM$semilla_primigenia,\n",
        "    \"'\" )\n",
        "\n",
        "  linea <- paste( comando, competencia, arch, mensaje)\n",
        "\n",
        "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
        "  cat(salida, \"\\n\")\n",
        "  Sys.sleep(45)\n",
        "}"
      ],
      "metadata": {
        "id": "gWW3tatE12je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ],
      "metadata": {
        "id": "B9tB2X4439Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "9zA_W25c15DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar-05**\n",
        "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
      ],
      "metadata": {
        "id": "UdVZucdLHzZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seguramente usted realice varias corridas de este script con distintos conjuntos de hiperparámetros, siempre cambiandole el nombre al script  y también cambiando el nombre del experimento,  deberá TODAS esas corridas en distintas lineas de la  Google Sheet Colaborativa, hoja **TareaHogar-05**"
      ],
      "metadata": {
        "id": "5MB_67DmDTh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Siéntase libre de agregar columnas a la hoja **TareaHogar-05**  en caso de ser necesario."
      ],
      "metadata": {
        "id": "OnRUS_PhFI1Z"
      }
    }
  ]
}